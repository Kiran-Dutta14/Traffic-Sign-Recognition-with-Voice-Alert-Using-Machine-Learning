# Traffic-Sign-Recognition-with-Voice-Alert-Using-Machine-Learning

ABSTRACT

	In today’s fast-paced world, road safety remains a paramount concern, with traffic violations and accidents often rooted in drivers overlooking or misinterpreting traffic signs. The increasing volume of vehicles on roads, coupled with human limitations such as fatigue or distraction, significantly raises the risk of missing critical traffic cues. To address this challenge, our project introduces an intelligent, assistive system that not only recognizes traffic signs using machine learning but also provides real-time voice alerts, thereby enhancing driver awareness and promoting safer driving behaviour.

	The primary problem tackled in this project is the delayed or missed recognition of traffic signs by drivers, which can lead to severe consequences including accidents or traffic rule violations. Especially in unfamiliar territories or in low-visibility conditions, relying solely on visual cues poses a risk. By augmenting visual sign recognition with audio feedback, this system offers an extra layer of awareness that supports both new and experienced drivers.

	Our approach begins with leveraging the German Traffic Sign Recognition Benchmark (GTSRB), a publicly available dataset comprising thousands of labeled images of various traffic signs. This dataset was chosen for its rich diversity in traffic sign categories and high-quality image data. The images were preprocessed and used to train a convolutional neural network (CNN), a powerful deep learning model known for its accuracy in image classification tasks. The CNN architecture was designed to extract relevant spatial features and patterns from traffic sign images, allowing the model to classify them into their respective categories with high confidence.

	Once the model was trained and validated, it was integrated into a Python-based application using the Keras framework. The system also features a simple yet functional graphical user interface (GUI) built with Tkinter, which allows users to interact with the model by selecting an image of a traffic sign. Upon classification, the system immediately plays an audio message describing the detected sign. This is achieved using the pyttsx3 library for text-to-speech synthesis, which converts the predicted label into a human-like voice alert.

	The system’s effectiveness was tested by feeding a variety of traffic sign images into the application, assessing both the classification accuracy and the clarity of the corresponding voice alerts. The results were promising: the model demonstrated a high recognition rate across multiple sign categories, including speed limits, warnings, prohibitions, and directional signs. More importantly, the addition of voice feedback proved to be a valuable enhancement, especially in scenarios where the driver might not be able to glance at the visual display.
